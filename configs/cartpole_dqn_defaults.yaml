# Path: configs/cartpole_dqn_defaults.yaml
# Purpose: Default baseline configuration for CartPole-v1 DQN runs.

# --- Experiment Description (Optional but Recommended) ---
description: "Baseline DQN configuration for CartPole-v1"

# --- Environment Configuration ---
environment:
  name: "CartPole-v1"      # Gymnasium environment name
  max_episode_steps: 500   # Default max steps for CartPole-v1 (v0 was 200)
  render_mode: null        # Optional: "human" or "rgb_array" (as needed)

# --- Network Configuration (MLP for DQN) ---
network:
  type: "MLP"              # Network type identifier
  # layers:                  # (This structure depends on how your MLP parses the config)
  #   - type: Dense1
  #     units: 32           # Hidden units in the first layer (adjust as needed)
  #     activation: relu
  #     kernel_initializer: he_uniform
  #   - type: Dense2
  #     units: 64           # Hidden units in the second layer (adjust as needed)
  #     activation: relu
  #     kernel_initializer: he_uniform

# --- Memory Configuration (Replay Buffer) ---
memory:
  capacity: 40000          # Replay buffer capacity

# --- Agent Configuration (DQN) ---
agent:
  name: "Step1B_DQNAgent"         # Agent name (for logs/identification)
  gamma: 0.99              # Discount factor
  learning_rate: 0.0005     # Learning rate (Adam optimizer)
  # Epsilon Greedy Strategy Parameters
  epsilon_start: 1.0             # Initial exploration rate
  epsilon_decay: 0.9999          # Exploration decay factor (multiplicative)
  epsilon_min: 0.01              # Minimum exploration rate
  # Target Network Update Parameters
  tau: 0.005               # Soft update coefficient (if using soft updates)
  # target_update_freq: 100 # Hard update frequency (training steps) - usually choose either this or tau

# --- Training Configuration ---
training:
  num_episodes: 500          # Total training episodes
  batch_size: 128            # Batch size sampled from replay buffer
  initial_collect_size: 1000 # Collect enough samples before training (improves diversity)
  main_seed: 42              # RNG seed for reproducibility (recommended from the start)

evaluator: 
  n_eval: 70 # Standard evaluation protocol